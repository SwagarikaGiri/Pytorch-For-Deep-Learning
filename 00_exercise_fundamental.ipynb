{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00. PyTorch Fundamentals Exercises\n",
    "\n",
    "### 1. Documentation reading \n",
    "\n",
    "A big part of deep learning (and learning to code in general) is getting familiar with the documentation of a certain framework you're using. We'll be using the PyTorch documentation a lot throughout the rest of this course. So I'd recommend spending 10-minutes reading the following (it's okay if you don't get some things for now, the focus is not yet full understanding, it's awareness):\n",
    "  * The documentation on [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch-tensor).\n",
    "  * The documentation on [`torch.cuda`](https://pytorch.org/docs/master/notes/cuda.html#cuda-semantics)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a random tensor with shape `(7, 7)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tensor_rand = torch.rand(7,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Perform a matrix multiplication on the tensor from 2 with another random tensor with shape `(1, 7)` (hint: you may have to transpose the second tensor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.1603],\n",
      "        [1.9645],\n",
      "        [1.6453],\n",
      "        [1.2805],\n",
      "        [2.0138],\n",
      "        [1.5912],\n",
      "        [2.4935]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "tensor_rand_A = torch.rand(7,7)\n",
    "tensor_rand_B = torch.rand(1,7)\n",
    "print(torch.matmul(tensor_rand_A,tensor_rand_B.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Set the random seed to `0` and do 2 & 3 over again.\n",
    "\n",
    "The output should be:\n",
    "```\n",
    "(tensor([[1.8542],\n",
    "         [1.9611],\n",
    "         [2.2884],\n",
    "         [3.0481],\n",
    "         [1.7067],\n",
    "         [2.5290],\n",
    "         [1.7989]]), torch.Size([7, 1]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5985]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "RANDOM_SEED = 0\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "tensor_rand_A = torch.rand(1,7)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "tensor_rand_B = torch.rand(1,7)\n",
    "print(torch.matmul(tensor_rand_A,tensor_rand_B.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Speaking of random seeds, we saw how to set it with `torch.manual_seed()` but is there a GPU equivalent? (hint: you'll need to look into the documentation for `torch.cuda` for this one)\n",
    "  * If there is, set the GPU random seed to `1234`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1272, 0.8167, 0.5440],\n",
      "        [0.6601, 0.2721, 0.9737]], device='cuda:0')\n",
      "tensor([[0.7154, 0.2908],\n",
      "        [1.1616, 0.3998]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "RANDOM_SEED = 1234\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "tensor_rand_A = torch.rand(2,3,device=device)\n",
    "print(tensor_rand_A)\n",
    "tensor_rand_B = torch.rand(3,2,device=device)\n",
    "print(torch.matmul(tensor_rand_A,tensor_rand_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor(0.1272, device='cuda:0')\n",
      "tensor(0.9737, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "rand_tensor = torch.arange(1,10)\n",
    "print(rand_tensor)\n",
    "print(torch.min(tensor_rand_A))\n",
    "print(torch.max(tensor_rand_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmin(tensor_rand_A))\n",
    "print(torch.argmax(tensor_rand_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0290, 0.4019, 0.2598, 0.3666, 0.0583, 0.7006, 0.0518, 0.4681,\n",
      "           0.6738, 0.3315]]]])\n",
      "torch.Size([1, 1, 1, 10])\n",
      "tensor([0.0290, 0.4019, 0.2598, 0.3666, 0.0583, 0.7006, 0.0518, 0.4681, 0.6738,\n",
      "        0.3315])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 1234\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "rand_tensor = torch.rand(1,1,1,10)\n",
    "print(rand_tensor)\n",
    "print(rand_tensor.shape)\n",
    "rand_dim = rand_tensor.squeeze()\n",
    "print(rand_dim)\n",
    "print(rand_dim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
